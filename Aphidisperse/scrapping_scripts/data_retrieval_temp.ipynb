{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading weather data\n",
    "\n",
    "Loading dataset with the DL links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, zipfile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "os.chdir(r\"C:\\Subpbiotech_cours\\BT4\\iGEM\\Dry_lab\\Model_prediction\\weather_data\")\n",
    "\n",
    "df = pd.read_csv(\"DL_links_dep.csv\")\n",
    "\n",
    "index_to_drop = [index for index, row in enumerate(df[\"title\"].to_list()) if (\"RR-T-Vent\" and \"2023\") not in row]\n",
    "index_to_drop += [index for index, row in enumerate(df[\"title\"].to_list()) if (\"RR-T-Vent\") not in row] \n",
    "\n",
    "df = df.drop(index=index_to_drop)\n",
    "serie_dep = df[\"title\"]\n",
    "serie_url = df[\"url\"]\n",
    "\n",
    "dico_dep_url = dict(zip(serie_dep, serie_url))\n",
    "\n",
    "os.chdir(r\"C:\\Subpbiotech_cours\\BT4\\iGEM\\Dry_lab\\Model_prediction\\weather_data\\2023\")\n",
    "current = os.getcwd()\n",
    "\n",
    "for key, url in dico_dep_url.items():\n",
    "    os.chdir(r\"C:\\Subpbiotech_cours\\BT4\\iGEM\\Dry_lab\\Model_prediction\\weather_data\\2023\")\n",
    "    urlretrieve(url, f\"{key}.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gzip, shutil, fnmatch\n",
    "\n",
    "os.chdir(r\"C:\\Subpbiotech_cours\\BT4\\iGEM\\Dry_lab\\Model_prediction\\weather_data\\2023\")\n",
    "current = os.getcwd()\n",
    "\n",
    "def gunzip(file_path,output_path):\n",
    "    with gzip.open(file_path,\"rb\") as f_in, open(output_path,\"wb\") as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "def recurse_and_gunzip(root):\n",
    "    walker = os.walk(root)\n",
    "    for root,dirs,files in walker:\n",
    "        for f in files:\n",
    "            if fnmatch.fnmatch(f,\"*.gz\"):\n",
    "                gunzip(f,f.replace(\".gz\",\"\"))\n",
    "\n",
    "recurse_and_gunzip(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir():\n",
    "    if file.endswith(\".gz\"):\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acronyme | Signification\n",
    "--- | --- \n",
    "NUM_POSTE   | ~~numéro Météo-France du poste sur 8 chiffres~~\n",
    "NOM_USUEL   | nom usuel du poste\n",
    "LAT         | latitude, négative au sud (en degrés et millionièmes de degrés)\n",
    "LON         | longitude, négative Ã  l'ouest de GREENWICH (en degrés et millionièmes de degrÃ©)\n",
    "ALTI        | ~~altitude du pied de l'abri ou du pluviomètre si pas d'abri (en m)~~\n",
    "AAAAMMJJ    | date de la mesure (année mois jour)\n",
    "RR          | quantité de précipitation tombée en 24 heures.\n",
    "TN          | ~~température minimale sous abri (en °C et 1/10)~~\n",
    "HTN         | ~~heure de TN (hhmm)~~\n",
    "TX          | ~~température maximale sous abri (en Â°C et 1/10)~~\n",
    "HTX         | ~~heure de TX (hhmm)~~\n",
    "TM          | ~~moyenne quotidienne des températures horaires sous abri (en Â°C et 1/10)~~\n",
    "TNTXM       | moyenne quotidienne (TN+TX)/2 (en °C et 1/10)\n",
    "TAMPLI      | amplitude thermique quotidienne : écart entre TX et TN quotidiens (TX-TN) (en Â°C et 1/10)\n",
    "TNSOL       | ~~température quotidienne minimale à 10 cm au-dessus du sol (en °C et 1/10)~~\n",
    "TN50        | ~~température quotidienne minimale à 50 cm au-dessus du sol (en °C et 1/10)~~\n",
    "DG          | durée de gel sous abri (T en °C) (en mn)\n",
    "FFM         | moyenne quotidienne de la force du vent moyennée sur 10 mn, Ã  10 m (en m/s et 1/10)\n",
    "FF2M        | moyenne quotidienne de la force du vent moyennée sur 10 mn, Ã  2 m (en m/s et 1/10)\n",
    "FXY         | maximum quotidien de la force maximale horaire du vent moyennée sur 10 mn, Ã  10 m (en m/s et 1/10)\n",
    "DXY         | direction de FXY (en rose de 360)\n",
    "HXY         | ~~heure de FXY (hhmm)~~\n",
    "FXI         | ~~maximum quotidien de la force maximale horaire du vent instantanée, Ã  10 m (en m/s et 1/10)~~\n",
    "DXI         | ~~direction de FXI (en rose de 360)~~\n",
    "HXI         | ~~heure de FXI (hhmm)~~\n",
    "FXI2        | maximum quotidien de la force maximale horaire du vent instantanée, Ã  2 m (en m/s et 1/10)\n",
    "DXI2        | direction de FXI2 (en rose de 360)\n",
    "HXI2        | heure de FXI2 (hhmm)\n",
    "FXI3S       | ~~maximum quotidien de la force maximale horaire du vent moyennée sur 3 s, Ã  10 m (en m/s et 1/10)~~\n",
    "DXI3S       | ~~direction de FXI3S (en rose de 360)~~\n",
    "HXI3S       | ~~heure de FXI3S (hhmm)~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NUM_POSTE;NOM_USUEL;LAT;LON;ALTI;AAAAMMJJ;RR;QRR;TN;QTN;HTN;QHTN;TX;QTX;HTX;QHTX;TM;QTM;TNTXM;QTNTXM;TAMPLI;QTAMPLI;TNSOL;QTNSOL;TN50;QTN50;DG;QDG;FFM;QFFM;FF2M;QFF2M;FXY;QFXY;DXY;QDXY;HXY;QHXY;FXI;QFXI;DXI;QDXI;HXI;QHXI;FXI2;QFXI2;DXI2;QDXI2;HXI2;QHXI2;FXI3S;QFXI3S;DXI3S;QDXI3S;HXI3S;QHXI3S;DRR;QDRR'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os, zipfile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "os.chdir(r\"C:\\Subpbiotech_cours\\BT4\\iGEM\\Dry_lab\\Model_prediction\\weather_data\\2023\")\n",
    "current = os.getcwd()\n",
    "\n",
    "df = pd.read_csv(\"QUOT_departement_01_periode_2023-2024_RR-T-Vent.csv\", sep=',')\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Subpbiotech_cours\\BT4\\iGEM\\Dry_lab\\Model_prediction\\weather_data\\2023\")\n",
    "current = os.getcwd()\n",
    "\n",
    "[\"NOM_USUEL\",\"LAT\", \"LON\", \"AAAAMMJJ\", \"RR\", \"TNTXM\" ,\"TAMPL\", \"DG\" ,\"FFM\", \"FF2M\" ,\"FXY\", \"DXY\", \"FXI2\", \"DXI2\", \"HXI2\" ]\n",
    "n=0\n",
    "\n",
    "for index, file in enumerate(os.listdir()):\n",
    "    df_temp = pd.read_csv(file, sep=';')\n",
    "    df_temp = df_temp[df_temp[\"AAAAMMJJ\"] > 20000101]\n",
    "    df_temp = df_temp.drop([\"QTNSOL\",\"QTN50\",\n",
    "                             \"QDG\", \"QFFM\", \"QFF2M\", 'QFXY', \"QDXY\",\"QHXY\",\"QFXI\",\"QDXI\",\"QHXI\", \"QFXI2\",\n",
    "                             \"QDXI2\", \"QHXI2\" ,\"QFXI3S\",\"QDXI3S\",\"QHXI3S\",\n",
    "                             \"ALTI\",  \"TNSOL\", \"TN50\", \"HXY\", \"FXI\",\n",
    "                             \"DXI\", \"HXI\", \"FXI3S\", \"DXI3S\", \"HXI3S\",\"FFM\", \"FF2M\" ,\"FXY\", \"DXY\", \"FXI2\", \"DXI2\", \"HXI2\",\"TAMPLI\", \"DG\"], axis=1)\n",
    "    \n",
    "    df_temp = df_temp[df_temp[\"RR\"].notna()]\n",
    "    os.remove(file)\n",
    "    df_temp.to_csv(rf\"C:\\Subpbiotech_cours\\BT4\\iGEM\\Dry_lab\\Model_prediction\\weather_data\\2023\\{file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "(1147259, 23)\n"
     ]
    }
   ],
   "source": [
    "df_global = pd.DataFrame()\n",
    "for index, file in enumerate(os.listdir()):\n",
    "    print(index)\n",
    "    df_temp = pd.read_csv(file, sep=',')\n",
    "    df_global = pd.concat([df_global, df_temp])\n",
    "print(df_global.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'NUM_POSTE', 'NOM_USUEL', 'LAT', 'LON', 'AAAAMMJJ', 'TNTXM']\n"
     ]
    }
   ],
   "source": [
    "df_global = df_global.drop(['TN', 'QTN', 'HTN', 'QHTN', 'TX', 'QTX', 'HTX', 'QHTX', 'TM', 'QTM', 'QTNTXM', 'QTAMPLI','RR', 'QRR','DRR', 'QDRR'], axis=1)\n",
    "print(list(df_global.columns))\n",
    "#assert list(df_global.columns) == [\"NOM_USUEL\",\"LAT\", \"LON\", \"AAAAMMJJ\", \"RR\", \"TNTXM\" ,\"TAMPL\", \"DG\" ,\"FFM\", \"FF2M\" ,\"FXY\", \"DXY\", \"FXI2\", \"DXI2\", \"HXI2\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global.to_csv(r\"C:\\Subpbiotech_cours\\BT4\\iGEM\\Dry_lab\\Model_prediction\\weather_data\\2023_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
